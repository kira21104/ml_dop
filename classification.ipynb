{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на Кагл: https://www.kaggle.com/kira2110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Titanic survival prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/titanic/data. Download the dataset and place it in the data/titanic/ folder in your working directory. You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/titanic/overview/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "...            ...    ...               ...      ...   ...      ...  \n",
       "887              0      0            211536  13.0000   NaN        S  \n",
       "888              0      0            112053  30.0000   B42        S  \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890              0      0            111369  30.0000  C148        C  \n",
       "891              0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prim = data\n",
    "data_prim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.5 points) How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male: 0\n",
      "female: 0\n",
      "survived: 342\n"
     ]
    }
   ],
   "source": [
    "male = data['Sex'].tolist().count('male')\n",
    "female = data['Sex'].tolist().count('female')\n",
    "print(f\"male: {male}\")\n",
    "print(f\"female: {female}\")\n",
    "\n",
    "survived = data['Survived'].tolist().count(1)\n",
    "print(f\"survived: {survived}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass     -0.338481\n",
       "Age        -0.077221\n",
       "SibSp      -0.035322\n",
       "Parch       0.081629\n",
       "Fare        0.257307\n",
       "Survived    1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Корреляция\n",
    "correlations_data = data.corr()['Survived'].sort_values()\n",
    "correlations_data\n",
    "#как видно здесь нет нужной нам корреляции, ибо пол - категориальный признак (делала в части model, гдн избавлялась от категориальности и считала корреляцию)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляция Пирсона показывает, что возраст совсем немного коррелирует с выживанием, но поскольку -0.077221 ближе к 0, то можно сказать, что связь мала.\n",
    "Для пола корреляция -0.543351, что довольно много, можно сделать вывод, что зависимость между полом и выживаемостью есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.5 points) Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxyklEQVR4nO3deXxV1bn4/89zTmYyj4QMJEAQEJEhAha1ihPYgdpaFQestUWv2un229bbe7/3W2/v91frt6O9FofWVlvH1lapRal11soQFJCASAxDQgJJgCQEMuf5/XF27DEmJCfkZJ9z8rxfPa9k773WOc8qMU/WWnuvJaqKMcYYM1QetwMwxhgTXixxGGOMCYglDmOMMQGxxGGMMSYgljiMMcYEJMrtAEZDZmamFhUVuR2GMcaElU2bNjWoalbf82MicRQVFVFWVuZ2GMYYE1ZEZG9/522oyhhjTEAscRhjjAmIJQ5jjDEBCWriEJElIrJTRCpE5LZ+rouI3OVc3yoic53zcSKyQUS2iEi5iNzuV+d7IrJfRDY7r0uC2QZjjDEfFrTJcRHxAncDFwLVwEYRWa2q2/2KLQVKnNcCYJXztR1YrKotIhINvC4iz6rqOqfeT1X1R8GK3RhjzMCC2eOYD1SoaqWqdgCPAcv6lFkGPKQ+64BUEcl1jlucMtHOy1ZjNMaYEBDMxJEHVPkdVzvnhlRGRLwishmoA55X1fV+5W51hrYeEJG0/j5cRFaKSJmIlNXX159kU4wxxvQKZuKQfs717TUMWEZVu1V1NpAPzBeRmc71VcBkYDZQC/y4vw9X1ftUtVRVS7OyPvL8ijHGmGEKZuKoBgr8jvOBmkDLqGoj8DKwxDk+6CSVHuB+fENixhhjRkkwnxzfCJSISDGwH7gSuKpPmdX4hp0ewzcp3qSqtSKSBXSqaqOIxAMXAD8EcOZAap36lwLbgtgG45JH1u8bctmrFhQGMRJjTF9BSxyq2iUitwJrAS/wgKqWi8hNzvV7gDXAJUAFcBy43qmeCzzo3JnlAZ5Q1Weca3eKyGx8Q1p7gBuD1QZjjDEfFdS1qlR1Db7k4H/uHr/vFbiln3pbgTkDvOe1IxymMcaYANiT48YYYwJiicMYY0xALHEYY4wJiCUOY4wxAbHEYYwxJiCWOIwxxgTEEocxxpiAWOIwxhgTEEscxhhjAmKJwxhjTEAscRhjjAmIJQ5jjDEBscRhjDEmIJY4jDHGBMQShzHGmIBY4jDGGBMQSxzGGGMCYonDGGNMQIK6dawxwdba0c0LOw7S3NZJfLSX0/JTyUuNdzssYyKaJQ4Tlg61tLN2+0HK9zehfa7Nyk/h+kVFLDs9D49HXInPmEhmicOEnc1VjTz5VjVeEc4uyeTm86aQkxxHU2snZXsO89jGKr7x+BYeenMvd35uFiU5SW6HbExECeoch4gsEZGdIlIhIrf1c11E5C7n+lYRmeucjxORDSKyRUTKReR2vzrpIvK8iOxyvqYFsw0mtLxR0cATZVUUpCXwrxdNZcnMXBZOyqA4cxyzC1L50tmTeP4b5/CTy09n36HjLLv7DZ7ZWuN22MZElKAlDhHxAncDS4EZwHIRmdGn2FKgxHmtBFY559uBxap6OjAbWCIiC51rtwEvqGoJ8IJzbMaAHbXNrHmnlhm5yXxxURHJcdH9lhMRPjs3n2e/djbTc5O59ZG3+c0bu0c5WmMiVzB7HPOBClWtVNUO4DFgWZ8yy4CH1GcdkCoiuc5xi1Mm2nmpX50Hne8fBD4TxDaYEHGopZ3Hy6qYkBrP5aUFRHkH/9HNTo7j0S8vZMmp47n9L9v51WuVoxCpMZEvmHMceUCV33E1sGAIZfKAWqfHsgmYAtytquudMjmqWgugqrUikt3fh4vISny9GAoLC0+yKcZNqsrTm2sQ4OoFhcREfThpPLJ+3wnrL5qSSXVjK//91x28d7CFOy+bFcRojYl8wexx9Hc7S98bYAYso6rdqjobyAfmi8jMQD5cVe9T1VJVLc3Kygqkqgkxm6saqahv4eJTx5OaEBNwfa9HuHxePsWZ43hyUzWb9h4OQpTGjB3B7HFUAwV+x/lA31nKQcuoaqOIvAwsAbYBB53hrFoRyQXqRjpwEzo6u3tYW36A/LR45henD/t9orwerlkwkbtfruD632zklvOmkDTAHElfVy2wHqsx/oLZ49gIlIhIsYjEAFcCq/uUWQ2scO6uWgg0OQkhS0RSAUQkHrgAeNevznXO99cBTwexDcZlG/ccprmti4tmjMcjJ/dMRnyMl6sXFNLa2c0fyqrp0b4dYGPMUAQtcahqF3ArsBbYATyhquUicpOI3OQUWwNUAhXA/cDNzvlc4CUR2YovAT2vqs841+4ALhSRXcCFzrGJQJ3dPbzyXj1FGeOYnDVuRN4zNyWeT5w2gYr6FtZVHhqR9zRmrAnqA4CqugZfcvA/d4/f9wrc0k+9rcCcAd7zEHD+yEZqQtGWqkaOtnVxeWkBcpK9DX9nFKWxo7aZ57YdoCQ7iayk2BF7b2PGAlvk0IQkVWVd5SFykmOZlDkyvY1evuc88ojyCk9t3o/akJUxAbHEYUJS1eHj1DS1sXBSxoj2NnolxUWz9NRcdjcc4619R0b8/Y2JZJY4TEhat/swsVEeZuenBu0z5hWlMTE9gefKD9LW2R20zzEm0ljiMCHnWHsX5TVNnJ6fSmy0N2if4xHhE7NyOdbexau76oP2OcZEGkscJuQ8v/0gnd3K6QWpQf+s/LQEZuWn8EZFA02tnUH/PGMigSUOE3Ke3ryflPhoJmYkjMrnXTRjPD0Kf99+cFQ+z5hwZ4nDhJRDLe28uquB0/NTT/qBv6FKHxfDmZMyeGvfEWqbWkflM40JZ7aRkxkVgy1E2GvjnsN09yiz8lOCHNGHnXdKNpv2HuG5bQe4flHxqH62MeHGehwmpOyobSY1IZrclLhR/dz4GC/nTM1iV10L1UeOj+pnGxNuLHGYkNHR1UNFXQvTc5OD8uzGYBYUpxMX7eGlnXaHlTEnYonDhIyKuha6epTp45Nd+fy4aC8fm5zJjtpmDjS1uRKDMeHAEocJGTtqm4mL9lA8wkuMBOJjkzKI8Xp4+T1brd+YgVjiMCFBVdl58ChTc5LwekZ/mKpXQmwUC4rTeae6iUMt7a7FYUwos8RhQsKB5jZa2rsoyU50OxQWlWTi9QivvGdzHcb0xxKHCQkVdS0ATMlOcjkSSI6LZt7ENN6uauRomz1NbkxfljhMSKioayErKZaU+KFt5xpsH5ucSXePsmG37U9uTF+WOIzrOrt72N1wjCkhMEzVKysplqk5iazffZj2Lls51xh/ljiM6/YeOk5Xj1KSFTqJA3y9jpb2Lv66tdbtUIwJKZY4jOt2N7TgEVy9Dbc/JdmJZCXG8ps39tgugcb4scRhXLe74RgTUuODuvfGcIgIZ07O4J39TbZLoDF+bJFD46rO7h6qjrRy5qQMt0Pp19zCNP62/QDfW72d5fMLh1TnqgVDK2dMuApqj0NElojIThGpEJHb+rkuInKXc32riMx1zheIyEsiskNEykXka351vici+0Vks/O6JJhtMMFVdeQ43T0acsNUvWKiPJROTKe8polm2+jJGCCIiUNEvMDdwFJgBrBcRGb0KbYUKHFeK4FVzvku4JuqOh1YCNzSp+5PVXW281oTrDaY4NvTcAwBijJCM3EAzC9Op0ehbK8NVxkDwe1xzAcqVLVSVTuAx4BlfcosAx5Sn3VAqojkqmqtqr4FoKpHgR1AXhBjNS7Z3XCMnOQ44mNCa37DX2ZiLJOzxlG25zA9NkluTFATRx5Q5XdczUd/+Q9aRkSKgDnAer/TtzpDWw+ISFp/Hy4iK0WkTETK6utt6YhQ1KNK1eHWUdsi9mTML86gsbWTXQePuh2KMa4LZuLob6W6vn+unbCMiCQCTwJfV9Vm5/QqYDIwG6gFftzfh6vqfapaqqqlWVlZAYZuRsPB5jY6unsoTA/9xDEjN5nE2CjW25PkxgQ1cVQDBX7H+UDNUMuISDS+pPGwqv6pt4CqHlTVblXtAe7HNyRmwlD1Yd/+3gVhkDi8HmHexDR2HjhK4/EOt8MxxlXBTBwbgRIRKRaRGOBKYHWfMquBFc7dVQuBJlWtFd/2b78GdqjqT/wriEiu3+GlwLbgNcEE074jx4mP9pIxLsbtUIbkjKJ0wCbJjQla4lDVLuBWYC2+ye0nVLVcRG4SkZucYmuASqACX+/hZuf8IuBaYHE/t93eKSLviMhW4DzgG8FqgwmuqsPHKUiPd2Wb2OFIHxdDSU4iZXsO091jk+Rm7ArqA4DOrbJr+py7x+97BW7pp97r9D//gapeO8JhGhe0dXZTf7Sd0/JS3A4lIGcUpfPw+n1U1B3lFJe2uDXGbbbkiHHF/sZWlPCY3/B3yvgkxsV4bbjKjGmWOIwrqg4fByA/Ld7lSAIT5fEwpzCNd2uP0tLe5XY4xrjCEodxRdXh42QmxpAQE37Lpc2dmEa3KluqGt0OxRhXWOIwo05VqTrSSkFaeA1T9RqfHEd+Wjyb9h6x5dbNmGSJw4y6xuOdtLR3kR9m8xv+5k1M40BzG/sbW90OxZhRZ4nDjLqqI775jYIwm9/wd3p+KlEeYZNNkpsxyBKHGXVVh48T5RHGp8S5HcqwxUV7mZmXwpbqRjq7e9wOx5hRZYnDjLqqI61MSI0nyhPeP37zJqbR1tlDeU3z4IWNiSDh/V+uCTvdPUpNY2tYD1P1Ks4cR1pCNJv22sKHZmyxxGFGVX1LO109yoTU8E8cHhHmTkzj/fpjHDlmCx+ascMShxlVtc5dSLkRkDjAtye5AJv22SS5GTsscZhRVdPYSpRHyEqMdTuUEZGWEMPk7ETe2nvEdgc0Y4YlDjOqapraGJ8Sh9cTHiviDsW8iWk0tnZSWX/M7VCMGRWWOMyoUVVqm1rJTYmMYapeM3KTiYv2UGaT5GaMsMRhRs2R4520dfYwITV8n9/oT7TXw+yCVLbXNNPa0e12OMYEnSUOM2pqm3wT4xMirMcBMG9iOl09yubqRrdDMSboLHGYUVPT2IYAOcmR1eMAyEuNJzcljrI9NlxlIp8lDjNqaptayUqKJSYqMn/sSovSqW1qY9v+JrdDMSaoIvO/YBOSahpbI+LBv4HMdhY+fHxjlduhGBNUQ0ocIvKkiHxCRCzRmGFpae+iua2L3DBe2HAw8TFeTp2QzFOb99PWaZPkJnINNRGsAq4CdonIHSIyLYgxmQjU+8R4JPc4wDdcdbSti2e31bodijFBM6TEoap/V9WrgbnAHuB5EfmHiFwvItED1RORJSKyU0QqROS2fq6LiNzlXN8qInOd8wUi8pKI7BCRchH5ml+ddBF5XkR2OV/TAm20GX01TW0AEd3jAN/Ch4XpCTZcZSLakIeeRCQD+ALwJeBt4Of4EsnzA5T3AncDS4EZwHIRmdGn2FKgxHmtxNezAegCvqmq04GFwC1+dW8DXlDVEuAF59iEuJrGVlITosNyj/FAeES4vDSfdZWH2XvIniQ3kWmocxx/Al4DEoBPqeqnVfVxVf0KkDhAtflAhapWqmoH8BiwrE+ZZcBD6rMOSBWRXFWtVdW3AFT1KLADyPOr86Dz/YPAZ4bSBuOu2qbWiHx+oz+XzSvAI/BEmfU6TGQaao/jV6o6Q1V/oKq1ACISC6CqpQPUyQP8/8up5p+//IdcRkSKgDnAeudUTm8Mztfs/j5cRFaKSJmIlNXX1w/SPBNMx9q7ONTSQW6EPTE+kPEpcXx8ahZ/3FRNl+0OaCLQUBPHf/dz7s1B6vS3il3f5UNPWEZEEoEnga+rakDbrKnqfapaqqqlWVlZgVQ1I2xHbTNKZD4xPpArzijgYHM7r7xnf7SYyHPCAWcRGY+vBxAvInP45y/6ZHzDVidSDRT4HecDNUMt40y6Pwk8rKp/8itzsHc4S0RygbpB4jAu691aNdLvqPK3eFoOmYkxPL6xivOn57gdjjEjarAex8XAj/D9Qv8J8GPn9a/AdwepuxEoEZFiEYkBrgRW9ymzGljh3F21EGhyEoIAvwZ2qOpP+qlznfP9dcDTg8RhXFZe00RCjJfkuMieGPcXE+Xhs3PzefHdOuqPtrsdjjEj6oSJQ1UfVNXzgC+o6nl+r0/36QX0V7cLuBVYi29y+wlVLReRm0TkJqfYGqASqADuB252zi8CrgUWi8hm53WJc+0O4EIR2QVc6BybEFZe08yElHh8fw+MHZeXFtDVo/zprWq3QzFmRA02VHWNqv4eKBKRf+17vZ/eQN/ra/AlB/9z9/h9r8At/dR7nf7nP1DVQ8D5J/pcEzo6unp47+BRFk7KcDuUUTclO5F5E9N4fGMVK8+ZNOYSp4lcgw1VjXO+JgJJ/byMOaFddUfp7NYxNTHu74ozCqhsOMaG3bZqrokcJ+xxqOq9ztfbRyccE2m2OxPjY+VW3L4+OSuX7z+znd+v38eCMdjrMpFpqA8A3ikiySISLSIviEiDiFwT7OBM+CuvaSY+2ktmYqzbobgiISaKz88r4LlttdQdbXM7HGNGxFCf47jIeY7ik/huoZ0KfCtoUZmIsb2mmem5SXjG8Pj+1QsL6exWnrD1q0yEGGri6F3I8BLgUVW1AVszqJ4eZXttM6dOSHE7FFdNzkrkrCmZPLJ+nz1JbiLCUBPHX0TkXaAUeEFEsgDrd5sT2nf4OC3tXZw6IdntUFx3zcKJ1DS18eK79ryqCX9DXVb9NuBMoFRVO4FjfHTBQmM+pPeJ8bHe4wC4YHo245Pj+N26vW6HYsxJC2RHv+nAFSKyArgMuCg4IZlIUV7TRJRHmDp+oAWUx44or4erFhTy2q4GKutb3A7HmJMy1Luqfodv6ZGzgDOc10Cr4hoD+HocU7ITiY3yuh1KSLhyfgExXg+/eWOP26EYc1KGunhQKTDDedLbmCEpr2nm41NtZeJe2UlxLJs9gT9squJfL5xK2rgYt0MyZliGOlS1DRgfzEBMZKlrbqOhpd0mxvu44exi2jp7eGTDPrdDMWbYhpo4MoHtIrJWRFb3voIZmAlvvRPjM/NsYtzftPHJnF2SyW//sYf2rm63wzFmWIY6VPW9YAZhIs+2/U0AzLAex0d8+exJrHhgA3/ZUstl8/LdDseYgA31dtxXgD1AtPP9RuCtIMZlwty2miaKM8eRGDt29uAYqrNLMjklJ4lfvVaJTRuacDTUu6q+DPwRuNc5lQc8FaSYTATYtr/Z5jcGICLccHYx7x44ymu7GtwOx5iADXWO4xZ8mys1A6jqLiA7WEGZ8NZ4vIP9ja02v3ECy2ZPYHxyHL94cZf1OkzYGWriaFfVjt4DEYkC7Kfd9OuDiXF7YnxAsVFe/uXcyWzcc4R1lbb0mwkvQ00cr4jId4F4EbkQ+APwl+CFZcJZ78S4DVWd2BVnFJCdFMtdL+xyOxRjAjLUxHEbUA+8A9yIbzvY/whWUCa8ldc0k5cabw+4DSIu2suNH5/Mm5WHbIdAE1aGdMuLqvaIyFPAU6paH9yQTLjbVtM0pnsbj6wf+sN9V80vZNXL7/OLF3fxuxsWBDEqY0bOCXsc4vM9EWkA3gV2iki9iPzn6IRnws2x9i52NxyzFXGHKD7Gy43nTOK1XQ1s2mu9DhMeBhuq+jq+u6nOUNUMVU0HFgCLROQbg725iCwRkZ0iUiEit/VzXUTkLuf6VhGZ63ftARGpE5Ftfep8T0T2i8hm53XJUBpqRseO2mZUYWbe2O1xBOrqhYVkJcVyx7Pv2h1WJiwMljhWAMtVdXfvCVWtBK5xrg1IRLzA3cBSYAawXERm9Cm2FChxXiuBVX7XfgssGeDtf6qqs53XmkHaYEZR78S43Yo7dAkxUXzjgqls3HOEteUH3Q7HmEENljiiVfUjTyg58xzR/ZT3Nx+oUNVK51bex/jo5k/LgIfUZx2QKiK5zme8CljfPcxsq2kmMzGG7KRYt0MJK5eX5jMlO5EfPvcunba9rAlxgyWOjmFeA9/T5VV+x9XOuUDL9OdWZ2jrARFJ66+AiKwUkTIRKauvt/n80VJe49tjXETcDiWsRHk9/NvSaexuOBbQ5LoxbhgscZwuIs39vI4Cpw1St7/fHH0HcIdSpq9VwGRgNlAL/Li/Qqp6n6qWqmppVpbtCTEa2jq72XXwqM1vDNPiadmcOSmDn/39PZrbOt0Ox5gBnTBxqKpXVZP7eSWp6mBDVdVAgd9xPlAzjDJ9Yzqoqt2q2gPcj29IzISAHbXNdPUop9n8xrCICP/+iekcOd7Jz/9uDwWa0BXInuOB2giUiEixiMQAVwJ99/BYDaxw7q5aCDSpau2J3rR3DsRxKb5NpkwI2FzVCMDsgn5HD80QzMxLYfn8Qn7zxu4PbjQwJtQELXGoahdwK7AW2AE8oarlInKTiNzkFFsDVAIV+HoPN/fWF5FHgTeBU0SkWkRucC7dKSLviMhW4Dxg0NuCzejYXNXI+OQ4xqfEuR1KWLttyTTSx8Xy3T+/Q3eP3Z5rQk9QN0twbpVd0+fcPX7fK76Vd/uru3yA89eOZIzhJNBJ06sWFAYpkv5trmpkdkHqqH5mJEpJiOY/PzWDrz76Ng+9uYfrFxW7HZIxHxLMoSozhhxqaWfvoePMLkx1O5SI8KlZuZwzNYsfrd1JbVOr2+EY8yGWOMyI2FLdCGA9jhEiIvz3spl0q/LtP26lx4asTAixxGFGxOZ9jXgEu6NqBBVmJPDvl0zntV0N/PYfe9wOx5gPWOIwI+Ltqkam5iQxzvYYH1HXLJzI+dOyueO5d3n3QLPb4RgDWOIwI6CnR9lS1cicQrsNd6SJCD+8bBbJcdF87dHNtHV2ux2SMZY4zMnbfegYzW1dzLH5jaDITIzlR5+fxc6DR/n+M9vdDscYSxzm5G3e1whgd1QF0bmnZHPjOZN4eP0+niirGryCMUFkicOctLerjpAYG8XkrES3Q4lo37r4FBZNyeA/ntrGVucuNmPcYInDnLTNVY3Myk/B67EVcYMpyuvhF8vnkpUYy02/20RDS7vbIZkxyhKHOSltnd28W3vUnt8YJenjYrj32nkcOtbBv/x+k02WG1fYvZPmpGypaqSrR+2OqmEa7t4bl87J47GNVVx+75tcXlqAZ4D9T0Z72RkzNljiMCdlw+7DiMAZRZY4RtOs/FQaj3fyXPkB0hJiuPjU8W6HZMYQSxzmpKzffZhTcpJITYhxO5Qx5+ySTA4f6+CV9+pJS4hhfnG62yGZMcLmOMywdXb3sGnvERZOynA7lDFJRPjU6ROYmpPI6i37ee/gUbdDMmOEJQ4zbO/sb6K1s5sF9peua7weYfkZheQkx/HIhn3UNNpKuib4LHGYYVtfeRiAMyxxuCo22suKM4uIj/by0Jt7aDze4XZIJsJZ4jDDtq7yEFOyE8lMjHU7lDEvJT6a684sor2rh4fe3Gu36ZqgssRhhqW9q5v1uw9x1pRMt0MxjvEpcVy1oJC6o208smGfbTtrgsbuqjLDcudzO2nr7KFHddjPIpiRV5KdxKVz8njyrf08tXk/1ywsRAZ4xsOY4bIehxmWXQeP4hWhOHOc26GYPuZNTOe8U7LZtPcId79U4XY4JgJZj8MMy666FgozEoiN8rodiunHBdOzaTzewY/+9h75aQl8Zk6e2yGZCBLUHoeILBGRnSJSISK39XNdROQu5/pWEZnrd+0BEakTkW196qSLyPMissv5ao8sj7L6o+3UNrVRkm2r4YYqEeHSuXmcOSmDb/1xCxt2H3Y7JBNBgpY4RMQL3A0sBWYAy0VkRp9iS4ES57USWOV37bfAkn7e+jbgBVUtAV5wjs0oemlnHQBTc5JcjsScSJTHwz3XzqMgLYGbH95EbZM942FGRjCHquYDFapaCSAijwHLAP8tzJYBD6mqAutEJFVEclW1VlVfFZGift53GXCu8/2DwMvAd4LTBNOfv5UfIDU+mtyUOLdDMYP469ZaPn36BFa98j6fv+dNvnz2JKK9A/+9aIsimqEI5lBVHuC/VVm1cy7QMn3lqGotgPM1u79CIrJSRMpEpKy+vj6gwM3AjrV38equBqZPSLa7dcJEdnIcn59XQPWRVp7eXIPv7zRjhi+YiaO/3yp9f2KHUmZYVPU+VS1V1dKsrKyReEsDvPpePR1dPZyam+x2KCYAMyYks3haNm/tO8K6ykNuh2PCXDATRzVQ4HecD9QMo0xfB0UkF8D5WneScZoArC0/QFpCNBMz7DbccLN4WjbTxifx13dq2d1wzO1wTBgLZuLYCJSISLGIxABXAqv7lFkNrHDurloINPUOQ53AauA65/vrgKdHMmgzsOMdXTy//SAXzRhv28SGIY8Il5cWkD4ulkc27KOptdPtkEyYClriUNUu4FZgLbADeEJVy0XkJhG5ySm2BqgEKoD7gZt764vIo8CbwCkiUi0iNziX7gAuFJFdwIXOsRkFz207wLGObj43L9/tUMwwxUV7uWZBIZ1dPTxmy5KYYQrqA4CqugZfcvA/d4/f9wrcMkDd5QOcPwScP4JhmiF68q1qCtLjKZ2YRkVdi9vhmGHKTo7j0rl5PL6xirXlB7jktFy3QzJhxpYcMUNS09jKP94/xGfn5OOxYaqwd3p+KgsnZfB6RQPv7G9yOxwTZixxmCH53bq9AFxmw1QR45LTxlOQFs+f3qqm4Wi72+GYMGKJwwzqWHsXD6/by8UzxlOQnuB2OGaERHk8LJ9fiNcjPLxhLx1dPW6HZMKEJQ4zqD+UVdHc1sWXzyl2OxQzwlITYriitIC65nae3rzfHg40Q2KJw5xQW2c397+2mzmFqcybaFvERqKSnCQWT8vm7apGHtlge6uYwVniMCf069d3s7+xlW9fPM3tUEwQnTctm5LsRG5fvZ2t1Y1uh2NCnCUOM6C65jZ++VIFF83I4czJGW6HY4Ko9+HAzMQY/uX3b9F4vMPtkEwIs8Rh+tXdo3zzD1vo6lH+7ZLpbodjRsG42Ch+ec086o628Y3HN9NjDweaAVjiiCCqysHmNrbXNLGlqpGXd9ZxsLltWO/1ixd38dquBm7/9Km2PewYMrsglf/85Axe2lnPL1+2bWdN/2zr2AjQ1dPDuvcPsX73YQ4d++cQw+NlvhXrizISuOS0XD45awLTc5NOuBy6qnL3SxX87O+7+OycPK44o2DAsiYyXbNwImV7j/CT599jdkEaZ5Vkuh2SCTGWOMLcgeY2Htuwj7qj7RRljOOcqVnkpsQRE+XhY5MzeWd/Ey/vrOPeVyv55cvvMylrHEtOHc+SmeM5LS/lQ0mksr6FHzz7Ls9vP8ilc/L44WWzbM+NMUhE+MFnT2N7TTNffext/vrVs8hNiXc7LBNCLHGEsYq6Fh5ev5eYKA8rFk5kWp89MuYXpzO/OJ0bzirmUEs7z5Uf4Nl3DnyQRDLGxTAlO5HYaC81ja1U1LWQEOPlO0umceM5k2xpkTEsISaKVdfMY9n/vM7Khzbx+I0LSYixXxfGx34SwtTeQ8d46M09ZCbGsuLMiaQmxJywfEZiLFcvmMjVCybSeLyDv++oY13lIXY3HKOttZOCtHiuKC3g07MnkJNsW8IamJKdyF3L5/Dlh8r4yiNvc++184g6wbazZuywxBGGGo6289Cbe0mJj+aLZxWTGBvYP2NqQgyXzcu3dafMoM6fnsPtnz6V//10Obf/ZTv/texUG740ljjCTWd3D49u3IcIXL8o8KRhTKCuPbOI6sZW7n2lktzUOG4+d4rbIRmX2W+dMPPstgPUNrWx4syJpI878fCUMSPlOxdP40BTG3c+t5PYKC83nGXrlo1lljjCSGVDC+sqD7FocgbTxicPXsGYEeLxCD/+/Ol0dPXw/We2E+URrvtYkdthGZfYTFeYaOvs5qm395OWEM2FM8a7HY4Zg6K8Hu5aPoeLZuTwf1aX8+A/9rgdknGJJY4wce8rlTS0dPCZ2XnERNk/m3FHtNfD/1w1lwum+5LHj9butKXYxyD7DRQGahpbWfVKBTPzUijJSXI7HDPGxUR5uOeauVxRWsD/vFTB//rDVjq7bROoscTmOMLAD597lx6FpafaEJUJrkfWD30/jjs+dxq5qXH87O+7ONDcyi+Wz7UbNsaIoPY4RGSJiOwUkQoRua2f6yIidznXt4rI3MHqisj3RGS/iGx2XpcEsw1u27a/iac31/Dls4tJs/8oTQgREb5+wVT+32Wz2LjnCJ/6xetsqWp0OywzCoLW4xARL3A3cCFQDWwUkdWqut2v2FKgxHktAFYBC4ZQ96eq+qNgxR5KfvL8e6TER3PjxyfzzJbaoH1OIH9pGuPv86UFnDI+iX/5/Vt8/p43+c9PzeDqBYX2oGAEC2aPYz5QoaqVqtoBPAYs61NmGfCQ+qwDUkUkd4h1I96mvUd48d06bvz4JJLjot0Ox5gBzcpP5ZmvnMXCyRn8x1Pb+PJDm2hoaXc7LBMkwZzjyAOq/I6r8fUqBiuTN4S6t4rICqAM+KaqHun74SKyElgJUFhYOMwmuOtHa3eSmRjLF4Z5v7z1IsxoShsXw2+/cAYPvLGbO9fuZMnPXuXOy2axeFqO26GZERbMHkd//dS+9+0NVOZEdVcBk4HZQC3w4/4+XFXvU9VSVS3NysoaUsCh5I2KBt6sPMQt5022VUlN2PB4hC+dPYm/3HoWmYmxfPG3ZXz3z+9wvKPL7dDMCArmb6RqwH8XoHygZohlYgaqq6oHe0+KyP3AMyMXcmhQVe5cu5MJKXFctSA8e0sm8g3Wo71qfiHP7zjIo+v3sXbbAe6/rpS5hWmjFJ0JpmD2ODYCJSJSLCIxwJXA6j5lVgMrnLurFgJNqlp7orrOHEivS4FtQWyDK/6+o44tVY189fwSYqO8bodjzLBEeT0snZnLDWcX063KZav+wU/+ttOe+YgAQetxqGqXiNwKrAW8wAOqWi4iNznX7wHWAJcAFcBx4PoT1XXe+k4RmY1v6GoPcGOw2uCGnh7lx3/bSVFGAp+zZc9NBJiUmchXF5ewvbaZu16s4KWd9fz0itOZkm0Ps4YrGQvLBZSWlmpZWZnbYQzJ6i01fPXRt/n5lbNZNjvvQ9dsstuEs6sWFPLctgN898/vcKy9i+8smcYXPlZkO02GMBHZpKqlfc/bkiMhpLO7h58+/x6n5CTxyVkT3A7HmBG3ZOZ4nvv62Zw1JZP/emY71z6wnprGVrfDMgGy23VCyJObqtndcIz7V5Titb/CTITx7zEvnpZNclw0f32nlsU/fplL5+RzWl7Kh8rbjSGhy3ocIaKts5ufv7CLOYWpXDA92+1wjAkqEeGM4nS+sngKWYmxPLphH396q5qOLps4DweWOELE79ftpbapjW9dfIot1WDGjIzEWFaeM5mPT81i094j3P1SBbVNNnQV6ixxhICW9i5++fL7nDUlk49NznQ7HGNGldcjXHzqeL54VjFtXd388uX3+cf7DbbPRwizxBEC7n+1ksPHOvjWxae4HYoxrpmc5btttyQ7kWe21nLDg2UcsvWuQpIlDpdVHznOPa+8zydm5XJ6Qarb4RjjqnGxUVy7cCKfmpXL6xUNLP35a7xR0eB2WKYPSxwu+79/3YFHhH+/ZLrboRgTEkSEMydn8tTNi0iKi+KaX6/njmfftSfOQ4glDhe9vquBZ7cd4JbzJjMhNd7tcIwJKTMmJPPMV87myjMKueeV97nsnjfZe+iY22EZLHG4prO7h+/9pZzC9AS+dPYkt8MxJiTFx3j5wWdP45dXz2V3fQtLfvYa977yvvU+XGaJwyW/eWM3FXUt/J9PzSAu2hYyNOZELjktl+e+fg6LpmTyg2ff5VO/eJ1Nez+yDY8ZJZY4XFBR18KP//YeF0zP5vzptsmNMUMxITWeX11Xyr3XzqPxeCefW/UPbn54E5X1LW6HNubYkiOjrKu7h2/+YQvxMV7+v0tPczscY8LOxaeOZ9GUTH71WiX3vVrJ2vKDXF6az8pzJlOcOc7t8MYESxyj7P+t3cmWqkb+56o5ZCfHuR2OMWEpMTaKr18wlasXTOQXL+7isQ1VPLahium5yZw1JZOJGQknXIHB1sE6OZY4RtFz22q599VKrllYaKvfGjMCspJi+a9lM7l18RS+/cetrK88zPbaZrKSYimdmMacwjQSY+3X3Eiz/0dHydv7jvD1xzdzekEq//uTM9wOx5iQF+j+MxfNGM+5U7PZWt1I2d4jPLvtAGvLDzApK5HT8lI4NTeZBEsiI8L+XxwFOw8c5YYHy8hOiuNXK0ptO1hjgiQmykNpUTqlRekcbG5jc1Uj2/Y38ee39/P05v1MzkpkxoRkFk/LZnyKDRUPlyWOINta3ciKBzYQ4/Xw4Bfnk5UU63ZIxowJOclxXHzqeC6akUNtUxvv7G/inf1NPL25hqc31zAzL5nzp+VwwfQcZuYl26rUAbDEEURPb97Pd57cSmZiLA9/aQETM+yOD2NGm4gwITWeCanxXDQjh7qj7cRGe3hhRx13vbiLn7+wi5zkWM6dms1ZJZl8bHIGGYn2B96JWOIIgiPHOvj+M9v509v7mV+Uzt1Xz7WehjEhQETISY7jqgWF3HzuFA61tPPSznpe2HGQNdtqebysCoAZucksmpLBvIlpnF6QSm6KLQnkzxLHCGpq7eT36/Zy7yvvc7yjm68unsJXzi8h2mvPWRoTijISY7lsXj6Xzcunq7uHbTXNvFHRwOu7GnjwH3u5/7XdAOQkx3J6fioz81KYlDWOSZmJFGeOIz5mbM5XBjVxiMgS4OeAF/iVqt7R57o41y8BjgNfUNW3TlRXRNKBx4EiYA9wuaq6tvZAc1snb75/iLXbDrBmWy1tnT2cPy2bby+Zxinjk9wKyxgToCivh9kFqcwuSOWW86bQ3tXN9ppmtlQ1sqW6iS1Vjfxt+8EP1ZmQEseE1Hiyk2PJTor759ekWNLHxZASH01KQjRJsVERNYcStMQhIl7gbuBCoBrYKCKrVXW7X7GlQInzWgCsAhYMUvc24AVVvUNEbnOOvxOMNrR1dnPkeAdNrZ00Hu+kqbWTpuOd7Dt8nPfrW3i/voVddS2oQnJcFJfOyePqBROZmZcSjHCMMSMkkFt9Y6K8nFGUzhlF6XR09XDoWDv1R9tpaGmnoaWDQ8c62HPoOEfbOmkfYM90j0ByfLQvkfTzGhcbRVy0l4QY3ys+2ktCTBTxMf88F+31EOURvB4hyuPB65UPjr0ieDyjl5iC2eOYD1SoaiWAiDwGLAP8E8cy4CH17RG5TkRSRSQXX29ioLrLgHOd+g8CLxOkxHH7X7bz6IaP/oB5PcLE9AQmZY3jktNymV/s+6GyISljIltMlIfclPgB5zw6uno42tbJgkkZHD7WQXOr8wdnn1djayfVR1o/OO7uOfltcj0CHhFEQBCc/3H/ilLOmZp10u/vL5iJIw+o8juuxterGKxM3iB1c1S1FkBVa0Uku78PF5GVwErnsEVEdg6nEQOpBF4ayTccXCYwVrZCs7ZGJmurCz7+f0+q+sT+TgYzcfTXb+qbVgcqM5S6J6Sq9wH3BVInlIlImaqWuh3HaLC2RiZra+QI5thKNVDgd5wP1AyxzInqHnSGs3C+1o1gzMYYYwYRzMSxESgRkWIRiQGuBFb3KbMaWCE+C4EmZxjqRHVXA9c5318HPB3ENhhjjOkjaENVqtolIrcCa/HdUvuAqpaLyE3O9XuANfhuxa3Adzvu9Seq67z1HcATInIDsA/4fLDaEGIiZthtCKytkcnaGiHEd0OTMcYYMzR2/6gxxpiAWOIwxhgTEEscIU5ElojIThGpcJ6UjxgiUiAiL4nIDhEpF5GvOefTReR5EdnlfE1zO9aRIiJeEXlbRJ5xjiOyrc7DvH8UkXedf98zI7it33B+freJyKMiEhepbe1liSOE+S29shSYASwXkUjaPrAL+KaqTgcWArc47etdVqYEeME5jhRfA3b4HUdqW38OPKeq04DT8bU54toqInnAV4FSVZ2J72aeK4nAtvqzxBHaPli2RVU7gN6lVyKCqtb2Lmqpqkfx/XLJw9fGB51iDwKfcSXAESYi+cAngF/5nY64topIMnAO8GsAVe1Q1UYisK2OKCBeRKKABHzPnEVqWwFLHKFuoCVZIo6IFAFzgPX0WVYG6HdZmTD0M+DbgP9KeJHY1klAPfAbZ1juVyIyjghsq6ruB36E79GAWnzPov2NCGyrP0scoe2kl14JByKSCDwJfF1Vm92OJxhE5JNAnapucjuWURAFzAVWqeoc4BgRNlTTy5m7WAYUAxOAcSJyjbtRBZ8ljtA2lGVbwpqIRONLGg+r6p+c05G4rMwi4NMisgffkONiEfk9kdnWaqBaVdc7x3/El0gisa0XALtVtV5VO4E/AR8jMtv6AUscoW0oy7aELWcjr18DO1T1J36XIm5ZGVX9N1XNV9UifP+OL6rqNURmWw8AVSJyinPqfHxbIkRcW/ENUS0UkQTn5/l8fHN1kdjWD9iT4yFORC7BNzbeu/TKyS2SHEJE5CzgNeAd/jnu/1188xxPAIU4y8qo6mFXggwCETkX+F+q+kkRySAC2yois/HdBBCDbxeC6/H9oRqJbb0duALfXYJvA18CEonAtvayxGGMMSYgNlRljDEmIJY4jDHGBMQShzHGmIBY4jDGGBMQSxzGGGMCYonDmCATkUtFREVkmtuxGDMSLHEYE3zLgdfxPfhnTNizxGFMEDnrcC0CbsBJHCLiEZFfOns4PCMia0TkMufaPBF5RUQ2icja3mUrjAklljiMCa7P4NuX4j3gsIjMBT4LFAGn4XvK+Ez4YN2uXwCXqeo84AEgYlYKMJEjyu0AjIlwy/EtGQO+xQ2XA9HAH1S1BzggIi85108BZgLP+5Y9wotvqW5jQoolDmOCxFmHajEwU0QUXyJQ4M8DVQHKVfXMUQrRmGGxoSpjgucy4CFVnaiqRapaAOwGGoDPOXMdOcC5TvmdQJaIfDB0JSKnuhG4MSdiicOY4FnOR3sXT+Lb8Kca2Abci2814CZne+DLgB+KyBZgM769HYwJKbY6rjEuEJFEVW1xhrM2AIucfSyMCXk2x2GMO54RkVR8+1V835KGCSfW4zDGGBMQm+MwxhgTEEscxhhjAmKJwxhjTEAscRhjjAmIJQ5jjDEB+f8BubzG3FGMwxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns_plot = sns.distplot(data['Age'])\n",
    "fig = sns_plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.343689655172415 28.0\n",
      "30.62617924528302 28.0\n"
     ]
    }
   ],
   "source": [
    "sur = data[(data['Survived'] == 1)]['Age'].mean()\n",
    "dead = data[(data['Survived'] == 0)]['Age'].mean()\n",
    "sur_m = data[(data['Survived'] == 1)]['Age'].median()\n",
    "dead_m = data[(data['Survived'] == 0)]['Age'].median()\n",
    "print(sur, sur_m)\n",
    "print(dead, dead_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1 point) Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 87 119\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## passenger class: 1 = 1-й, 2 = 2-й, 3 = 3-й\n",
    "clas1 = len(data[(data['Pclass'] == 1) & (data['Survived'] == 1)])\n",
    "clas2 = len(data[(data['Pclass'] == 2) & (data['Survived'] == 1)])\n",
    "clas3 = len(data[(data['Pclass'] == 3) & (data['Survived'] == 1)])\n",
    "print(clas1, clas2, clas3)\n",
    "h = data['Pclass'].hist()\n",
    "fig = h.get_figure()\n",
    "#Как видно из полученных данных, больше всего выживших из 1-го класса - 136 человек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 30 217\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## embarked: C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "#data['Embarked'] = data['Embarked'].map(data.groupby('Embarked').size())\n",
    "#data['Embarked']\n",
    "embC = len(data[(data['Embarked'] == 'C') & (data['Survived'] == 1)])\n",
    "embQ = len(data[(data['Embarked'] == 'Q') & (data['Survived'] == 1)])\n",
    "embS = len(data[(data['Embarked'] == 'S') & (data['Survived'] == 1)])\n",
    "print(embC, embQ, embS)\n",
    "h = data['Embarked'].hist()\n",
    "fig = h.get_figure()\n",
    "\n",
    "#В данном случае, больше всего выживших село на Титаник в порту Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 1 74\n",
      "9 2 76\n",
      "25 27 67\n"
     ]
    }
   ],
   "source": [
    "#Выжившие 1-го класса по портам C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "kol1 = len(data[(data['Pclass'] == 1) & (data['Survived'] == 1) & (data['Embarked'] == 'C')])\n",
    "kol2 = len(data[(data['Pclass'] == 1) & (data['Survived'] == 1) & (data['Embarked'] == 'Q')])\n",
    "kol3 = len(data[(data['Pclass'] == 1) & (data['Survived'] == 1) & (data['Embarked'] == 'S')])\n",
    "print(kol1, kol2, kol3)\n",
    "\n",
    "#Выжившие 2-го класса по портам C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "kol12 = len(data[(data['Pclass'] == 2) & (data['Survived'] == 1) & (data['Embarked'] == 'C')])\n",
    "kol22 = len(data[(data['Pclass'] == 2) & (data['Survived'] == 1) & (data['Embarked'] == 'Q')])\n",
    "kol32 = len(data[(data['Pclass'] == 2) & (data['Survived'] == 1) & (data['Embarked'] == 'S')])\n",
    "print(kol12, kol22, kol32)\n",
    "\n",
    "#Выжившие 3-го класса по портам C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "kol13 = len(data[(data['Pclass'] == 3) & (data['Survived'] == 1) & (data['Embarked'] == 'C')])\n",
    "kol23 = len(data[(data['Pclass'] == 3) & (data['Survived'] == 1) & (data['Embarked'] == 'Q')])\n",
    "kol33 = len(data[(data['Pclass'] == 3) & (data['Survived'] == 1) & (data['Embarked'] == 'S')])\n",
    "print(kol13, kol23, kol33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(0.5 points) Find the percentage of missing values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0.000000\n",
       "Pclass      0.000000\n",
       "Name        0.000000\n",
       "Sex         0.000000\n",
       "Age         0.198653\n",
       "SibSp       0.000000\n",
       "Parch       0.000000\n",
       "Ticket      0.000000\n",
       "Fare        0.000000\n",
       "Cabin       0.771044\n",
       "Embarked    0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts > Для числовых типов, вероятно, стоит заполнять пропуски средним, потому что затем будет считаться корреляция бинарной и вещественной переменной, а это делается через разность мат. ожиданий (E[X1|X2=1] - E[X1|X2=0]), то есть важно сохранить мат. ожидание неизменным.\n",
    "\n",
    "Для категориальных признаков корреляцию с бинарным признаком можно подсчитать с помощью коэффициента V Крамера:\n",
    "\n",
    "chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "n = confusion_matrix.sum()\n",
    "return np.sqrt(chi2 / (n*(min(confusion_matrix.shape)-1)))\n",
    "То есть на вход подается таблица сопряженности. Если данных достаточно, то я бы исключил все пропуски. Второй подход ввести новую категорию у каждого признака, например, \"no_value\", но в этом случае она также будет фигурировать в таблице сопряженности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1.5 points) Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex        -0.543351\n",
       "Pclass     -0.313463\n",
       "Embarked   -0.142741\n",
       "Age        -0.069809\n",
       "SibSp      -0.035322\n",
       "Parch       0.081629\n",
       "Fare        0.257307\n",
       "Survived    1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, RFECV, SequentialFeatureSelector\n",
    "\n",
    "y = data['Survived']\n",
    "\n",
    "#Categorical Features\n",
    "data['Pclass'] = data['Pclass'].map(data.groupby('Pclass').size())\n",
    "data['Sex'] = data['Sex'].map(data.groupby('Sex').size())\n",
    "data['Embarked'] = data['Embarked'].map(data.groupby('Embarked').size())\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "for feat in features:\n",
    "    data.fillna({feat: data[feat].mean()}, inplace=True)\n",
    "\n",
    "data[features]\n",
    "\n",
    "#Корреляция для задания выше\n",
    "correlations_data = data.corr()['Survived'].sort_values()\n",
    "correlations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_1 = data_prim.drop('Name', 1) \\ndata_new = data_1.drop('Ticket', 1)\\nprint(data_new)\\n\\n\\n#Находим важные функции\\nselection_model = RandomForestClassifier(random_state=42)\\nselector = SelectFromModel(selection_model).fit(data_new, y)\\ndata_pruned = selector.transform(data_new)\\nprint(data_new.columns[selector.get_support()])\\nprint(f'Original shape: {data_new.shape}')\\nprint(f'Shape after selection: {data_pruned.shape}')\\n\""
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_1 = data_prim.drop('Name', 1) \n",
    "data_new = data_1.drop('Ticket', 1)\n",
    "print(data_new)\n",
    "\n",
    "\n",
    "#Находим важные функции\n",
    "selection_model = RandomForestClassifier(random_state=42)\n",
    "selector = SelectFromModel(selection_model).fit(data_new, y)\n",
    "data_pruned = selector.transform(data_new)\n",
    "print(data_new.columns[selector.get_support()])\n",
    "print(f'Original shape: {data_new.shape}')\n",
    "print(f'Shape after selection: {data_pruned.shape}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    int64  \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     891 non-null    float64\n",
      " 10  Embarked  891 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(2)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7586980920314254\n",
      "0.920314253647587\n",
      "Кросс-валидация для логистической регрессии: {'fit_time': array([0.01700449, 0.01700377, 0.01700354, 0.01600361, 0.01600313]), 'score_time': array([0.00099993, 0.0010004 , 0.0010004 , 0.00100017, 0.00100064]), 'test_score': array([0.79329609, 0.79775281, 0.79775281, 0.78089888, 0.83707865])}\n",
      "\n",
      "Кросс-валидация для KNN: {'fit_time': array([0.00300097, 0.00300097, 0.00200057, 0.00200057, 0.00200033]), 'score_time': array([0.00500083, 0.00500059, 0.00600123, 0.00600147, 0.00500131]), 'test_score': array([0.76536313, 0.78651685, 0.79213483, 0.7752809 , 0.76404494])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Irisha-PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Без скалирования\n",
    "X = data[features]\n",
    "y = data['Survived']\n",
    "\n",
    "#Логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "data['Survived_pred'] = logreg.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred']))\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "type(knn)\n",
    "knn.fit(X, y)\n",
    "data['Survived_pred_knn'] = knn.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred_knn']))\n",
    "\n",
    "#Кросс-валидация\n",
    "print(f\"Кросс-валидация для логистической регрессии: {cross_validate(logreg, X, y, scoring='accuracy', cv=5)}\\n\")\n",
    "print(f\"Кросс-валидация для KNN: {cross_validate(knn, X, y, scoring='accuracy', cv=5)}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8069584736251403\n",
      "0.9001122334455668\n",
      "Кросс-валидация для логистической регрессии: {'fit_time': array([0.00200891, 0.00199986, 0.00200081, 0.00200033, 0.00199962]), 'score_time': array([0.       , 0.0010016, 0.       , 0.       , 0.       ]), 'test_score': array([0.81564246, 0.79213483, 0.79213483, 0.76404494, 0.8258427 ])}\n",
      "\n",
      "Кросс-валидация для KNN: {'fit_time': array([0.00100112, 0.00200033, 0.00099993, 0.0010004 , 0.00099969]), 'score_time': array([0.0040009 , 0.00400138, 0.00500131, 0.00400138, 0.00402927]), 'test_score': array([0.69832402, 0.73033708, 0.79213483, 0.74719101, 0.75280899])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Скалирование данных\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[features])\n",
    "data_scaled\n",
    "\n",
    "X = data_scaled\n",
    "y = data['Survived']\n",
    "\n",
    "#Логистическая регрессия\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "data['Survived_pred_scaled'] = logreg.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred_scaled']))\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "type(knn)\n",
    "knn.fit(X, y)\n",
    "data['Survived_pred_knn_scaled'] = knn.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred_knn_scaled']))\n",
    "\n",
    "#Кросс-валидация\n",
    "print(f\"Кросс-валидация для логистической регрессии: {cross_validate(logreg, X, y, scoring='accuracy', cv=5)}\\n\")\n",
    "print(f\"Кросс-валидация для KNN: {cross_validate(knn, X, y, scoring='accuracy', cv=5)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.5 + X points) Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024691358024691\n",
      "0.9225589225589226\n",
      "Кросс-валидация для логистической регрессии: {'fit_time': array([0.00400138, 0.0040009 , 0.0040009 , 0.00400043, 0.0040009 ]), 'score_time': array([0.00100017, 0.        , 0.        , 0.0010004 , 0.        ]), 'test_score': array([0.80446927, 0.80898876, 0.79213483, 0.74719101, 0.82022472])}\n",
      "\n",
      "Кросс-валидация для KNN: {'fit_time': array([0.00100064, 0.00100017, 0.00100017, 0.00200057, 0.0010004 ]), 'score_time': array([0.00500107, 0.00500107, 0.0040009 , 0.00400066, 0.0040009 ]), 'test_score': array([0.69273743, 0.75280899, 0.80898876, 0.76966292, 0.76966292])}\n"
     ]
    }
   ],
   "source": [
    "#Скалирование данных MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_min_max = scaler.fit_transform(data[features])\n",
    "\n",
    "X = data_min_max\n",
    "y = data['Survived']\n",
    "\n",
    "#Логистическая регрессия\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "data['Survived_pred_scaled_min_max'] = logreg.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred_scaled_min_max']))\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "type(knn)\n",
    "knn.fit(X, y)\n",
    "data['Survived_pred_knn_scaled_min_max'] = knn.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_pred_knn_scaled_min_max']))\n",
    "\n",
    "#Кросс-валидация\n",
    "print(f\"Кросс-валидация для логистической регрессии: {cross_validate(logreg, X, y, scoring='accuracy', cv=5)}\\n\")\n",
    "print(f\"Кросс-валидация для KNN: {cross_validate(knn, X, y, scoring='accuracy', cv=5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n",
      "0.9315375982042648\n",
      "Кросс-валидация для логистической регрессии: {'fit_time': array([0.00500178, 0.00500083, 0.00400114, 0.0040009 , 0.00400066]), 'score_time': array([0.        , 0.        , 0.        , 0.00100017, 0.        ]), 'test_score': array([0.81005587, 0.79775281, 0.79775281, 0.78089888, 0.84269663])}\n",
      "\n",
      "Кросс-валидация для KNN: {'fit_time': array([0.00198913, 0.00200105, 0.00100064, 0.00100064, 0.00100088]), 'score_time': array([0.00400043, 0.00400043, 0.00500083, 0.00500059, 0.00500059]), 'test_score': array([0.67039106, 0.73595506, 0.80898876, 0.74157303, 0.75280899])}\n"
     ]
    }
   ],
   "source": [
    "'''#Добавляем фичи\n",
    "features_new = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Cabin']\n",
    "\n",
    "data['Pclass'] = data['Pclass'].map(data.groupby('Pclass').size())\n",
    "data['Sex'] = data['Sex'].map(data.groupby('Sex').size())\n",
    "data['Embarked'] = data['Embarked'].map(data.groupby('Embarked').size())\n",
    "data['Cabin'] = data['Cabin'].map(data.groupby('Cabin').size())\n",
    "data['Cabin']\n",
    "\n",
    "for feat in features_new:\n",
    "    data.fillna({feat: data[feat].mean()}, inplace=True)\n",
    "\n",
    "data[features_new]\n",
    "\n",
    "#Скалирование данных MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_min_max_n = scaler.fit_transform(data[features_new])\n",
    "\n",
    "X = data_min_max_n\n",
    "y = data['Survived']\n",
    "\n",
    "#Логистическая регрессия\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "data['Survived_new_features'] = logreg.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_new_features']))\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "type(knn)\n",
    "knn.fit(X, y)\n",
    "data['Survived_knn_new_features'] = knn.predict(X)\n",
    "print(accuracy_score(data['Survived'], data['Survived_knn_new_features']))\n",
    "\n",
    "#Кросс-валидация\n",
    "print(f\"Кросс-валидация для логистической регрессии: {cross_validate(logreg, X, y, scoring='accuracy', cv=5)}\\n\")\n",
    "print(f\"Кросс-валидация для KNN: {cross_validate(knn, X, y, scoring='accuracy', cv=5)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test set and make the predictions. Submit them to kaggle and see the results :) Select the best model, load the test set and make the predictions. Submit them to kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. X points will depend on your kaggle leaderboard score.$$ f(score) = 0.5, \\ \\ 0.76 \\leq score &lt; 0.78,$$$$ f(score) = 1.0, \\ \\ 0.78 \\leq score &lt; 0.81,$$$$ f(score) = 2.5, \\ \\ 0.81 \\leq score $$Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = pd.read_csv(os.path.join(PATH, 'titanic', 'test.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Name      418 non-null    object \n",
      " 2   Sex       418 non-null    object \n",
      " 3   Age       332 non-null    float64\n",
      " 4   SibSp     418 non-null    int64  \n",
      " 5   Parch     418 non-null    int64  \n",
      " 6   Ticket    418 non-null    object \n",
      " 7   Fare      417 non-null    float64\n",
      " 8   Cabin     91 non-null     object \n",
      " 9   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 35.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tested.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>218</td>\n",
       "      <td>152</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>93</td>\n",
       "      <td>266</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>218</td>\n",
       "      <td>152</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>107</td>\n",
       "      <td>152</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>218</td>\n",
       "      <td>266</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Sex       Age  SibSp  Parch  Embarked\n",
       "PassengerId                                               \n",
       "892             218  266  34.50000      0      0        46\n",
       "893             218  152  47.00000      1      0       270\n",
       "894              93  266  62.00000      0      0        46\n",
       "895             218  266  27.00000      0      0       270\n",
       "896             218  152  22.00000      1      1       270\n",
       "...             ...  ...       ...    ...    ...       ...\n",
       "1305            218  266  30.27259      0      0       270\n",
       "1306            107  152  39.00000      0      0       102\n",
       "1307            218  266  38.50000      0      0       270\n",
       "1308            218  266  30.27259      0      0       270\n",
       "1309            218  266  30.27259      1      1       102\n",
       "\n",
       "[418 rows x 6 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested['Pclass'] = tested['Pclass'].map(tested.groupby('Pclass').size())\n",
    "tested['Sex'] = tested['Sex'].map(tested.groupby('Sex').size())\n",
    "tested['Embarked'] = tested['Embarked'].map(tested.groupby('Embarked').size())\n",
    "tested['Embarked']\n",
    "\n",
    "features_t = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "for feat_t in features_t:\n",
    "    tested.fillna({feat_t: tested[feat_t].mean()}, inplace=True)\n",
    "\n",
    "tested[features_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    int64  \n",
      " 2   Age       418 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Embarked  418 non-null    int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 22.9 KB\n"
     ]
    }
   ],
   "source": [
    "tested[features_t].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Скалируем тестовый набор\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "test_min_max = scaler.fit_transform(tested[features_t])\n",
    "test_min_max\n",
    "\n",
    "#KNN для тестовых данных (использовала первым, так как на трейне показал лучший результат 90%), но на Kaggle результат 68%\n",
    "X = test_min_max\n",
    "tested['test_pred'] = knn.predict(X)\n",
    "test_y = tested['test_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = knn.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('knn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Логистическая регрессия дала более приятный результат 77% на Kaggle\n",
    "X = test_min_max\n",
    "tested['pred_log'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = logreg.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('logreg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Изменим набор признаков\n",
    "features_new = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Cabin']\n",
    "\n",
    "tested['Pclass'] = tested['Pclass'].map(tested.groupby('Pclass').size())\n",
    "tested['Sex'] = tested['Sex'].map(tested.groupby('Sex').size())\n",
    "tested['Embarked'] = tested['Embarked'].map(tested.groupby('Embarked').size())\n",
    "tested['Cabin'] = tested['Cabin'].map(tested.groupby('Cabin').size())\n",
    "tested['Embarked']\n",
    "\n",
    "for feat_n in features_new:\n",
    "    tested.fillna({feat_n: tested[feat_n].mean()}, inplace=True)\n",
    "\n",
    "tested[features_new]\n",
    "\n",
    "#Скалирование данных MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "tested_min_max_n = scaler.fit_transform(tested[features_new])\n",
    "\n",
    "#KNN для тестовых данных 64%\n",
    "X = tested_min_max_n\n",
    "tested['test_pred_n'] = knn.predict(X)\n",
    "tested_y = tested['test_pred_n']\n",
    "\n",
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = knn.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('knn_new_features.csv',index=False)\n",
    "\n",
    "#Логистическая регрессия для новых признаков 75%\n",
    "X = tested_min_max_n\n",
    "tested['pred_log_n'] = logreg.predict(X)\n",
    "\n",
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = logreg.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('logreg_new_features.csv',index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Изменим набор признаков\n",
    "features_n = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Cabin']\n",
    "\n",
    "tested['Pclass'] = tested['Pclass'].map(tested.groupby('Pclass').size())\n",
    "tested['Sex'] = tested['Sex'].map(tested.groupby('Sex').size())\n",
    "tested['Embarked'] = tested['Embarked'].map(tested.groupby('Embarked').size())\n",
    "tested['Cabin'] = tested['Cabin'].map(tested.groupby('Cabin').size())\n",
    "tested['Embarked']\n",
    "\n",
    "for feat_n in features_n:\n",
    "    tested.fillna({feat_n: tested[feat_n].mean()}, inplace=True)\n",
    "\n",
    "    \n",
    "#Скалирование данных MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "tested_n = scaler.fit_transform(tested[features_n])\n",
    "\n",
    "#Логистическая регрессия для новых признаков 77%\n",
    "X = tested_n\n",
    "tested['log_pred'] = logreg.predict(X)\n",
    "\n",
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = logreg.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('logreg_all_features.csv',index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  Sex       Age  SibSp  Parch  Embarked\n",
      "PassengerId                                               \n",
      "892             218  266  34.50000      0      0        46\n",
      "893             218  152  47.00000      1      0       270\n",
      "894              93  266  62.00000      0      0        46\n",
      "895             218  266  27.00000      0      0       270\n",
      "896             218  152  22.00000      1      1       270\n",
      "...             ...  ...       ...    ...    ...       ...\n",
      "1305            218  266  30.27259      0      0       270\n",
      "1306            107  152  39.00000      0      0       102\n",
      "1307            218  266  38.50000      0      0       270\n",
      "1308            218  266  30.27259      0      0       270\n",
      "1309            218  266  30.27259      1      1       102\n",
      "\n",
      "[418 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#StandartScaler\n",
    "\n",
    "tested['Pclass'] = tested['Pclass'].map(tested.groupby('Pclass').size())\n",
    "tested['Sex'] = tested['Sex'].map(tested.groupby('Sex').size())\n",
    "tested['Embarked'] = tested['Embarked'].map(tested.groupby('Embarked').size())\n",
    "\n",
    "features1 = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
    "for feat1 in features1:\n",
    "    tested.fillna({feat1: tested[feat1].mean()}, inplace=True)\n",
    "\n",
    "print(tested[features1])\n",
    "\n",
    "#Скалирование данных\n",
    "scaler = StandardScaler()\n",
    "tested_sc = scaler.fit_transform(tested[features1])\n",
    "\n",
    "X = tested_sc\n",
    "\n",
    "#Логистическая регрессия со StandartScaler дала лучший результат на Kaggle - 0,77990\n",
    "tested['Survived_ss'] = logreg.predict(X)\n",
    "\n",
    "#Запись в файл\n",
    "sub = pd.read_csv(os.path.join(PATH, 'titanic', 'gender_submission.csv'))\n",
    "sub['Survived'] = logreg.predict(X)\n",
    "sub.head()\n",
    "sub.to_csv('logreg_ss.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Porto Seguro’s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. Read the detailed description and download the dataset https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data. Put the data into ./data/porto/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = pd.read_csv(os.path.join(PATH, 'porto', 'train.csv')).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                              \n",
       "7        0          2              2          5              1              0   \n",
       "9        0          1              1          7              0              0   \n",
       "13       0          5              4          9              1              0   \n",
       "16       0          0              1          2              0              0   \n",
       "17       0          0              2          0              1              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "id                                                              ...   \n",
       "7               0              1              0              0  ...   \n",
       "9               0              0              1              0  ...   \n",
       "13              0              0              1              0  ...   \n",
       "16              1              0              0              0  ...   \n",
       "17              1              0              0              0  ...   \n",
       "\n",
       "    ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "id                                                                   \n",
       "7            9           1           5           8               0   \n",
       "9            3           1           1           9               0   \n",
       "13           4           2           7           7               0   \n",
       "16           2           2           4           9               0   \n",
       "17           3           1           1           3               0   \n",
       "\n",
       "    ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "id                                                                   \n",
       "7                1               1               0               0   \n",
       "9                1               1               0               1   \n",
       "13               1               1               0               1   \n",
       "16               0               0               0               0   \n",
       "17               0               0               1               1   \n",
       "\n",
       "    ps_calc_20_bin  \n",
       "id                  \n",
       "7                1  \n",
       "9                0  \n",
       "13               0  \n",
       "16               0  \n",
       "17               0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip EDA for now. We'll use SGDClassifier and build a simple baseline: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html. Note that loss='log' gives logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = insurance_data['target']\n",
    "X = insurance_data.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [column for column in X if not (column.endswith(\"cat\") or column.endswith(\"bin\"))]\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = [column for column in X if (column.endswith(\"cat\") or column.endswith(\"bin\"))]\n",
    "categorical_transformer = Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', SGDClassifier(loss='log', alpha=0.001, n_jobs=-1, random_state=14))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631224658945812"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_valid, y_pred=clf.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our model gets ~0.963 accuracy! But is it really good?...\n",
    "\n",
    "Let's plot the confusion matrix and analyze the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(clf, X_valid, y_valid,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it turns out that our model is completely useless. Let's calculate some basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       1.900378       1.358943       4.423318   \n",
       "std         0.187401       1.983789       0.664594       2.699902   \n",
       "min         0.000000       0.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       1.000000       1.000000       4.000000   \n",
       "75%         0.000000       3.000000       2.000000       6.000000   \n",
       "max         1.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.416794       0.405188       0.393742       0.257033   \n",
       "std         0.493311       1.350642       0.488579       0.436998   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.163921       0.185304  ...       5.441382       1.441918   \n",
       "std         0.370205       0.388544  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you see, there are less than 4% of positive examples, so we have to deal with a highly imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='target', data=insurance_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Accuracy is not informative here and the Normalized Gini Coefficient will be used instead: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/overview/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for calculating Normalized gini coefficient\n",
    "# https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):  \n",
    "    assert(len(actual) == len(pred))  \n",
    "    epsilon = 1e-7\n",
    "    values = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)  \n",
    "    values = values[np.lexsort((values[:, 2], -1 * values[:, 1]))]  \n",
    "    total = values[:, 0].sum() \n",
    "    gini_sum = (values[:, 0].cumsum().sum() + epsilon) / (total + epsilon)  \n",
    "  \n",
    "    gini_sum -= (len(actual) + 1) / 2  \n",
    "    return gini_sum / len(actual)  \n",
    "  \n",
    "def gini_normalized(a, p):  \n",
    "    '''Function to calculate the normalized gini coefficient'''\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1.5 points) Prove that the Normalized Gini Coefficient is equivalent to 2 x AUC - 1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your proof >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.5 points) By the way, what other metrics could you suggest for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the Normalized Gini Coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2558723581569817"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_normalized(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.5 points + Y bonus points) Try different approaches: oversampling / undersampling, careful feature analysis and feature engineering, etc., to get a reasonable pipeline and improve the model quality. Use cross-validation for model evaluation.\n",
    "\n",
    "Select the best model, load the test set and make the predictions. Submit them to kaggle. Y bonus points will be calculated as $\\frac{round(200 * \\max(score - 0.253, 0))}{2}$, where score is your kaggle leaderboard score.\n",
    "\n",
    "Note: do not use any classification models which have not been covered in the lessons yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
